{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62f66cf3-c015-44e5-b8d2-5066ee0cd831",
   "metadata": {},
   "source": [
    "## ASTR 597A Homework 4\n",
    "Eric Bellm\n",
    "\n",
    "Due Jan 31, 2023"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2825ee37-aef9-4082-8d54-d0651614638b",
   "metadata": {},
   "source": [
    "Your name:\n",
    "    \n",
    "Your collaborators:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed28e99b",
   "metadata": {},
   "source": [
    "## Installation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19b5314c",
   "metadata": {},
   "source": [
    "This homework does not use the DP0.2 simulated data, and the `rubin_sim` package that includes the Metrics Analysis Framework (MAF) is not installed by default on `data.lsst.cloud`.  You may install and run `rubin_sim` on the `data.lsst.cloud` RSP instance, on your personal computer, or on a shared server like `epyc`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca499cc3",
   "metadata": {},
   "source": [
    "You will need to install the `rubin_sim` package according to the directions at https://github.com/lsst/rubin_sim."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00ae6b89",
   "metadata": {},
   "source": [
    "You can get more information about MAF from https://rubin-sim.lsst.io/ as well as the [rubin_sim_notebooks](https://github.com/lsst/rubin_sim_notebooks) tutorial notebooks; some of this material was adapted from those tutorials."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f08c1e88",
   "metadata": {},
   "source": [
    "Note that in late 2022 many of the APIs in MAF were changed, as discussed in the [release notes](https://github.com/lsst/rubin_sim/releases), so you may find older materials which require some adjustment to use."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "469680bb",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Let's confirm that rubin_sim is working and that we can use MAF on the current baseline cadence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f86578",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "621d9f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rubin_sim\n",
    "from rubin_sim import maf\n",
    "from rubin_sim.maf.run_comparison import archive\n",
    "rubin_sim.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b5241b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "opsim_fname = rubin_sim.data.get_baseline()\n",
    "print(opsim_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db3184c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import splitext, basename\n",
    "\n",
    "run_name = splitext(basename(opsim_fname))[0]\n",
    "print(run_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b64899c",
   "metadata": {},
   "source": [
    "At the time of this writing the baseline is `baseline_v3.0_10yrs`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d529dabc",
   "metadata": {},
   "source": [
    "Let's find a basic metric to run.  `CoaddM5` is provides the final coadded depth of the ten-year survey:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a895d906",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# list all pre-installed metrics\n",
    "# maf.BaseMetric.help()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca68618",
   "metadata": {},
   "outputs": [],
   "source": [
    "#help(maf.Coaddm5Metric)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27116f0a",
   "metadata": {},
   "source": [
    "Let's make plots of this metric for the `r` band as a spatial (healpix) map as well as a 1-d histogram, and then compute some summary statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea9da763",
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose the spatial slicer\n",
    "slicer = maf.slicers.HealpixSlicer(nside=64)\n",
    "\n",
    "# choose the metric\n",
    "metric =  maf.metrics.Coaddm5Metric()\n",
    "\n",
    "# only r-band\n",
    "constraint = \"filter = 'r'\"\n",
    "\n",
    "# choose how to plot\"\n",
    "plot_funcs = [maf.plots.HealpixSkyMap(), maf.plots.HealpixHistogram()]\n",
    "plot_dict = {'nside': 64, 'colorMin': 0}\n",
    "\n",
    "# define the summary metrics\n",
    "summary_metrics = [maf.metrics.MinMetric(), maf.metrics.MedianMetric(), maf.metrics.MaxMetric(), \n",
    "                 maf.metrics.PercentileMetric(percentile=25), maf.metrics.PercentileMetric(percentile=75)]\n",
    "\n",
    "# wrap it up\n",
    "bundle = maf.metricBundles.MetricBundle(metric, slicer, constraint=constraint, run_name=run_name,\n",
    "                                        plot_dict=plot_dict, plot_funcs=plot_funcs,\n",
    "                                        summary_metrics=summary_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "356e4bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir = 'example'\n",
    "\n",
    "bdict = {'example':bundle}\n",
    "bgroup = maf.metricBundles.MetricBundleGroup(bdict, opsim_fname, out_dir=out_dir)\n",
    "bgroup.run_all()\n",
    "bgroup.plot_all(closefigs=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96130e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "bdict['example'].summary_values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b3192c7",
   "metadata": {},
   "source": [
    "## Exercise 1: Counts\n",
    "\n",
    "Let's get a sense of how the LSST divides its exposures.  Use `UniSlicer`, `CountMetric`, and appropriate SQL constraints to provide counts of the total exposures by filter.  The OpSim schema is described [here](https://rubin-sim.lsst.io/rs_scheduler/output_schema.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "106778e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9406fee7",
   "metadata": {},
   "source": [
    "## Exercise 2: Cloudy\n",
    "\n",
    "What is the mean cloud cover for exposures taken during the simulated baseline survey?  Plot a histogram of the cloud cover."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d78a32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2bc66075",
   "metadata": {},
   "source": [
    "## Exercise 3: Comparisons\n",
    "\n",
    "MAF was built to compare evaluate the impact of different observing strategies on various science cases.  You can always write new metrics and run them yourself on multiple OpSim simulations.  This can be time consuming, though.  For many standard metrics, the metric values for various runs are stored in queryable tables--see the [04_Getting_Data](https://github.com/lsst/rubin_sim_notebooks/blob/main/maf/tutorial/04_Getting_Data.ipynb) tutorial notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa5778d",
   "metadata": {},
   "source": [
    "### 3a\n",
    "\n",
    "In this exercise we'll get a small taste of the tradeoffs confronted by the Survey Cadence Optimization Committee.\n",
    "\n",
    "Make a mesh plot of the metric summary values for the metric sets `\"DESC WFD\"` (Cosmology), `\"TVS XRB\"` (Galactic Transients), and `\"SSO discovery\"` (Solar System science) on run families `\"baseline\"`, `\"galactic plane footprint\"`, amd `\"rolling\"`.  Set `baseline_run='baseline_v2.0_10yrs'` to compare to one of the earlier baseline cadences.  Qualitatively, how does the new (v3.0) baseline cadence look for these metrics?  What other trends do you see across these run families?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "691f4ddf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9871e86d",
   "metadata": {},
   "source": [
    "### 3b (optional)\n",
    "\n",
    "Look through the list of metric sets and identify which one(s) are most closely associated with your scientific interests.  What has been the trend of these metrics in the `\"baseline\"` run family?  Make a plot with `maf.plot_run_metric`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da1fd8fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b7e340ac",
   "metadata": {},
   "source": [
    "## Exercise 4: Lightcurves\n",
    "\n",
    "Some metrics take simulated events and generate the data points as they would be observed by LSST.  Typically these lightcurves are only used internally to compute higher-level metrics, but some metrics make it possible to return the generated lightcurves."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e9a762",
   "metadata": {},
   "source": [
    "Use the `KNePopMetric` with `output_lc=True` to generate random kilonova lightcurves as observed by LSST.  Plot an event with at least ten data points.\n",
    "\n",
    "The [kilonova](https://github.com/lsst/rubin_sim_notebooks/blob/main/maf/science/KNeMetric.ipynb) and [XRB](https://github.com/lsst/rubin_sim_notebooks/blob/main/maf/science/XRB_Metric.ipynb) science notebooks will be helpful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d290fd43",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
